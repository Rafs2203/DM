{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> <br>\n",
    "\n",
    "#  <center> <b> Data Mining Project- ABCDEats Inc. </center> <br>\n",
    "## <center> Clustering Models </center> <br>\n",
    "### <center> Group 38 <center>\n",
    "\n",
    "  <div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group Members\n",
    "| Name              | Email                        | Student ID |\n",
    "|-------------------|------------------------------|------------|\n",
    "| Inês Araújo       | 20240532@novaims.unl.pt      | 20240532   |\n",
    "| Leonor Mira       | 20240658@novaims.unl.pt      | 20240658   |\n",
    "| Rafael Silva      | 20240511@novaims.unl.pt      | 20240511   |\n",
    "| Rita Serra        | 20240515@novaims.unl.pt      | 20240515   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### **2. Clustering Techniques Notebook**\n",
    "**Description:**\n",
    "In this notebook, we will experiment with and evaluate various clustering techniques to uncover patterns and groupings within the data. The focus will be on the following methods:\n",
    "\n",
    "- **Hierarchical Clustering:** Organizes the data into a hierarchy of clusters, providing insights into relationships at multiple levels of granularity.\n",
    "- **K-Means Clustering:** Partitions the data into a predefined number of clusters (`k`), optimizing similarity within each group.\n",
    "- **Self-Organizing Maps (SOMs):** Uses neural network-based methods to project high-dimensional data into a lower-dimensional map, revealing complex clustering patterns.\n",
    "\n",
    "Key steps include:\n",
    "- Loading the **dataset** for clustering analysis.\n",
    "- Applying **preprocessing and normalization** to prepare the data for clustering.\n",
    "- **Implementing clustering algorithms**: Experimenting with the three techniques mentioned above.\n",
    "- **Visualization and evaluation:** Visualizing cluster formations and analyzing their quality using metrics such as Silhouette Score.\n",
    "- **Comparison:** Comparing the strengths and limitations of each method.\n",
    "\n",
    "This notebook serves as a foundational exploration of clustering methods, providing insights into how different techniques handle the same dataset.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Table of Contents** <br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<a class=\"anchor\" id=\"importlibraries\">\n",
    "\n",
    "# 1. Import Libraries\n",
    "    \n",
    "</a>\n",
    "<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # Imports the pandas library, used for handling and analyzing structured data in tables (DataFrames).\n",
    "import numpy as np  # Imports numpy, which is helpful for working with numerical data, especially for mathematical functions and arrays.\n",
    "import matplotlib.pyplot as plt  # Imports matplotlib's pyplot module to create plots and charts for visualizing data.\n",
    "import seaborn as sns  # Imports seaborn, a library built on matplotlib, for creating more advanced and visually appealing statistical graphics.\n",
    "from math import ceil  # Imports the ceil function from the math library, which rounds numbers up to the nearest whole number.\n",
    "from scipy.stats import f_oneway # Import the f_oneway function from SciPy for performing a one-way ANOVA test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<a class=\"anchor\" id=\"importdataset\">\n",
    "    \n",
    "# 2. Import dataset\n",
    "    \n",
    "</a>\n",
    "<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\P'\n",
      "C:\\Users\\joaom\\AppData\\Local\\Temp\\ipykernel_17092\\3002583927.py:1: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  df = pd.read_csv('..\\Preprocessed_Data\\df.csv', index_col='customer_id')\n",
      "C:\\Users\\joaom\\AppData\\Local\\Temp\\ipykernel_17092\\3002583927.py:1: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('..\\Preprocessed_Data\\df.csv', index_col='customer_id')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('..\\Preprocessed_Data\\df.csv', index_col='customer_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 25\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Splitting feature names into groups\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Remember which metric_features we decided to keep?\u001b[39;00m\n\u001b[0;32m      3\u001b[0m metric_features \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcustomer_age\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      4\u001b[0m  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvendor_count\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      5\u001b[0m  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproduct_count\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m  \u001b[38;5;66;03m#daily_consumption\u001b[39;00m\n\u001b[0;32m     23\u001b[0m  ]\n\u001b[1;32m---> 25\u001b[0m CUI_metric_features \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcolumns[df\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUI_\u001b[39m\u001b[38;5;124m'\u001b[39m)]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m     26\u001b[0m DOW_metric_features \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcolumns[df\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDOW_\u001b[39m\u001b[38;5;124m'\u001b[39m)]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m     27\u001b[0m HR_metric_features \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcolumns[df\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHR_\u001b[39m\u001b[38;5;124m'\u001b[39m)]\u001b[38;5;241m.\u001b[39mtolist()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Splitting feature names into groups\n",
    "# Remember which metric_features we decided to keep?\n",
    "metric_features = ['customer_age',\n",
    " 'vendor_count',\n",
    " 'product_count',\n",
    " 'first_order',\n",
    " 'last_order',\n",
    " 'dif_order',\n",
    " 'tot_CUI',\n",
    " 'tot_work_days',\n",
    " 'tot_leisure_days',\n",
    " 'total_products_by_week',\n",
    " 'tot_early_morning',\n",
    " 'tot_breakfast',\n",
    " 'tot_lunch',\n",
    " 'tot_afternoon',\n",
    " 'tot_dinner',\n",
    " 'tot_late_night',\n",
    " 'tot_western_cuisines',\n",
    " 'tot_oriental_cuisines',\n",
    " 'tot_other_cuisines',\n",
    " #daily_consumption\n",
    " ]\n",
    "\n",
    "CUI_metric_features = df.columns[df.columns.str.startswith('CUI_')].tolist()\n",
    "DOW_metric_features = df.columns[df.columns.str.startswith('DOW_')].tolist()\n",
    "HR_metric_features = df.columns[df.columns.str.startswith('HR_')].tolist()\n",
    "\n",
    "#unused_features = [i for i in df.columns if i not in (metric_features+non_metric_features+pc_features) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('metric_features:', metric_features)\n",
    "print('CUI_metric_features:', CUI_metric_features)\n",
    "print('DOW_metric_features:', DOW_metric_features)\n",
    "print('HR_metric_features:', HR_metric_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<a class=\"anchor\" id=\"section_3\">\n",
    "    \n",
    "# 3. Hierarchical Clustering\n",
    "    \n",
    "</a>\n",
    "<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the linkage method to choose:\n",
    "### $SS_{t},  SS_{w}, SS_{b}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AgglomerativeClustering' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Performing HC\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m hclust \u001b[38;5;241m=\u001b[39m AgglomerativeClustering(linkage\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mward\u001b[39m\u001b[38;5;124m'\u001b[39m, metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meuclidean\u001b[39m\u001b[38;5;124m'\u001b[39m, n_clusters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m      3\u001b[0m hc_labels \u001b[38;5;241m=\u001b[39m hclust\u001b[38;5;241m.\u001b[39mfit_predict(df[metric_features]) \u001b[38;5;66;03m# CODE HERE\u001b[39;00m\n\u001b[0;32m      4\u001b[0m hc_labels\n",
      "\u001b[1;31mNameError\u001b[0m: name 'AgglomerativeClustering' is not defined"
     ]
    }
   ],
   "source": [
    "# Performing HC\n",
    "hclust = AgglomerativeClustering(linkage='ward', metric='euclidean', n_clusters=5)\n",
    "hc_labels = hclust.fit_predict(df[metric_features]) # CODE HERE\n",
    "hc_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Characterizing the clusters\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m labels_series \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(hc_labels, \n\u001b[0;32m      4\u001b[0m                           name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m      5\u001b[0m                           index\u001b[38;5;241m=\u001b[39mdf\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;66;03m# WHY df.index ??\u001b[39;00m\n\u001b[0;32m      6\u001b[0m                           ) \n\u001b[0;32m      8\u001b[0m df_concat \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df, labels_series],axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     10\u001b[0m df_concat[metric_features\u001b[38;5;241m+\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Characterizing the clusters\n",
    "\n",
    "labels_series = pd.Series(hc_labels, \n",
    "                          name='labels', \n",
    "                          index=df.index # WHY df.index ??\n",
    "                          ) \n",
    "\n",
    "df_concat = pd.concat([df, labels_series],axis=1)\n",
    "\n",
    "df_concat[metric_features+['labels']].groupby('labels').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ss(df, feats):\n",
    "    \"\"\"\n",
    "    Calculate the sum of squares (SS) for the given DataFrame.\n",
    "\n",
    "    The sum of squares is computed as the sum of the variances of each column\n",
    "    multiplied by the number of non-NA/null observations minus one.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The input DataFrame for which the sum of squares is to be calculated.\n",
    "    feats (list of str): A list of feature column names to be used in the calculation.\n",
    "\n",
    "    Returns:\n",
    "    float: The sum of squares of the DataFrame.\n",
    "    \"\"\"\n",
    "    df_ = df[feats]\n",
    "    ss = np.sum(df_.var() * (df_.count() - 1))\n",
    "    \n",
    "    return ss \n",
    "\n",
    "\n",
    "def get_ssb(df, feats, label_col):\n",
    "    \"\"\"\n",
    "    Calculate the between-group sum of squares (SSB) for the given DataFrame.\n",
    "    The between-group sum of squares is computed as the sum of the squared differences\n",
    "    between the mean of each group and the overall mean, weighted by the number of observations\n",
    "    in each group.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The input DataFrame containing the data.\n",
    "    feats (list of str): A list of feature column names to be used in the calculation.\n",
    "    label_col (str): The name of the column in the DataFrame that contains the group labels.\n",
    "    \n",
    "    Returns\n",
    "    float: The between-group sum of squares of the DataFrame.\n",
    "    \"\"\"\n",
    "    \n",
    "    ssb_i = 0\n",
    "    for i in np.unique(df[label_col]):\n",
    "        df_ = df.loc[:, feats]\n",
    "        X_ = df_.values\n",
    "        X_k = df_.loc[df[label_col] == i].values\n",
    "        \n",
    "        ssb_i += (X_k.shape[0] * (np.square(X_k.mean(axis=0) - X_.mean(axis=0))) )\n",
    "\n",
    "    ssb = np.sum(ssb_i)\n",
    "    \n",
    "\n",
    "    return ssb\n",
    "\n",
    "\n",
    "def get_ssw(df, feats, label_col):\n",
    "    \"\"\"\n",
    "    Calculate the sum of squared within-cluster distances (SSW) for a given DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The input DataFrame containing the data.\n",
    "    feats (list of str): A list of feature column names to be used in the calculation.\n",
    "    label_col (str): The name of the column containing cluster labels.\n",
    "\n",
    "    Returns:\n",
    "    float: The sum of squared within-cluster distances (SSW).\n",
    "    \"\"\"\n",
    "    feats_label = feats+[label_col]\n",
    "\n",
    "    df_k = df[feats_label].groupby(by=label_col).apply(lambda col: get_ss(col, feats), \n",
    "                                                       include_groups=False)\n",
    "\n",
    "    return df_k.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sst_ = get_ss(df_concat, metric_features)\n",
    "df_ssb_ = get_ssb(df_concat, metric_features, 'labels')\n",
    "df_ssw_ = get_ssw(df_concat, metric_features, 'labels')\n",
    "\n",
    "print(\"SSb:  \", df_ssb_)\n",
    "print(\"SSw:  \", df_ssw_)\n",
    "print(\"SSt:  \", df_sst_)\n",
    "print(\"SSt == SSb+SSw ? \", (df_sst_ == df_ssb_ + df_ssw_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $R^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_rsq(df, feats, label_col):\n",
    "    \"\"\"\n",
    "    Calculate the R-squared value for a given DataFrame and features.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input DataFrame containing the data.\n",
    "    feats (list): A list of feature column names to be used in the calculation.\n",
    "    label_col (str): The name of the column containing the labels or cluster assignments.\n",
    "\n",
    "    Returns:\n",
    "    float: The R-squared value, representing the proportion of variance explained by the clustering.\n",
    "    \"\"\"\n",
    "\n",
    "    df_sst_ = get_ss(df, feats)                 # get total sum of squares\n",
    "    df_ssw_ = get_ssw(df, feats, label_col)     # get ss within\n",
    "    df_ssb_ = df_sst_ - df_ssw_                 # get ss between\n",
    "\n",
    "    # r2 = ssb/sst \n",
    "    return (df_ssb_/df_sst_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the best Linkage method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_r2_hc(df, link_method, max_nclus, min_nclus=1, dist=\"euclidean\"):\n",
    "    \"\"\"This function computes the R2 for a set of cluster solutions given by the application of a hierarchical method.\n",
    "    The R2 is a measure of the homogenity of a cluster solution. It is based on SSt = SSw + SSb and R2 = SSb/SSt. \n",
    "    \n",
    "    Parameters:\n",
    "    df (DataFrame): Dataset to apply clustering\n",
    "    link_method (str): either \"ward\", \"complete\", \"average\", \"single\"\n",
    "    max_nclus (int): maximum number of clusters to compare the methods\n",
    "    min_nclus (int): minimum number of clusters to compare the methods. Defaults to 1.\n",
    "    dist (str): distance to use to compute the clustering solution. Must be a valid distance. Defaults to \"euclidean\".\n",
    "    \n",
    "    Returns:\n",
    "    ndarray: R2 values for the range of cluster solutions\n",
    "    \"\"\"\n",
    "    \n",
    "    r2 = []  # where we will store the R2 metrics for each cluster solution\n",
    "    feats = df.columns.tolist()\n",
    "    \n",
    "    for i in range(min_nclus, max_nclus+1):  # iterate over desired ncluster range\n",
    "        cluster = AgglomerativeClustering(n_clusters=i, metric=dist, linkage=link_method)\n",
    "        \n",
    "        #get cluster labels\n",
    "        hclabels = cluster.fit_predict(df) \n",
    "        \n",
    "        # concat df with labels\n",
    "        df_concat = pd.concat([df, pd.Series(hclabels, name='labels', index=df.index)], axis=1)  \n",
    "        \n",
    "        \n",
    "        # append the R2 of the given cluster solution\n",
    "        r2.append(get_rsq(df_concat, feats, 'labels'))\n",
    "        \n",
    "    return np.array(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_methods = [\"ward\", \"complete\", \"average\", \"single\"]\n",
    "max_nclus = 10\n",
    "\n",
    "r2_hc = np.vstack([ get_r2_hc(df[metric_features], \n",
    "                              link, \n",
    "                              max_nclus=max_nclus, \n",
    "                              min_nclus=1, \n",
    "                              dist=\"euclidean\") \n",
    "                              for link in hc_methods])\n",
    "r2_hc_methods = pd.DataFrame(r2_hc.T, index=range(1, max_nclus + 1), columns=hc_methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "\n",
    "# Plot data\n",
    "fig = plt.figure(figsize=(11,5))\n",
    "sns.lineplot(data=r2_hc_methods, linewidth=2.5, markers=[\"o\"]*4)\n",
    "\n",
    "# Finalize the plot\n",
    "plt.legend(title=\"HC methods\", title_fontsize=11)\n",
    "plt.xticks(range(1, max_nclus + 1))\n",
    "plt.xlabel(\"Number of clusters\", fontsize=13)\n",
    "plt.ylabel(\"R2 metric\", fontsize=13)\n",
    "\n",
    "fig.suptitle(\"$R^2$ plot for various hierarchical methods\", fontsize=21)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the number of clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting distance_threshold=0 and n_clusters=None ensures we compute the full tree\n",
    "linkage = 'ward'\n",
    "distance = 'euclidean'\n",
    "\n",
    "\n",
    "hclust = AgglomerativeClustering(linkage=linkage, metric=distance, distance_threshold=0, n_clusters=None)\n",
    "hclust.fit_predict(df[metric_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from:\n",
    "# https://scikit-learn.org/stable/auto_examples/cluster/plot_agglomerative_dendrogram.html#sphx-glr-auto-examples-cluster-plot-agglomerative-dendrogram-py\n",
    "\n",
    "# create the counts of samples under each node (number of points being merged)\n",
    "counts = np.zeros(hclust.children_.shape[0])\n",
    "n_samples = len(hclust.labels_)\n",
    "\n",
    "# hclust.children_ contains the observation ids that are being merged together\n",
    "# At the i-th iteration, children[i][0] and children[i][1] are merged to form node n_samples + i\n",
    "for i, merge in enumerate(hclust.children_):\n",
    "    # track the number of observations in the current cluster being formed\n",
    "    current_count = 0\n",
    "    for child_idx in merge:\n",
    "        if child_idx < n_samples:\n",
    "            # If this is True, then we are merging an observation\n",
    "            current_count += 1  # leaf node\n",
    "        else:\n",
    "            # Otherwise, we are merging a previously formed cluster\n",
    "            current_count += counts[child_idx - n_samples]\n",
    "    counts[i] = current_count\n",
    "\n",
    "# the hclust.children_ is used to indicate the two points/clusters being merged (dendrogram's u-joins)\n",
    "# the hclust.distances_ indicates the distance between the two points/clusters (height of the u-joins)\n",
    "# the counts indicate the number of points being merged (dendrogram's x-axis)\n",
    "linkage_matrix = np.column_stack(\n",
    "    [hclust.children_, hclust.distances_, counts]\n",
    ").astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the corresponding dendrogram\n",
    "sns.set()\n",
    "fig = plt.figure(figsize=(11,5))\n",
    "# The Dendrogram parameters need to be tuned\n",
    "y_threshold = 100\n",
    "dendrogram(linkage_matrix, truncate_mode='level', p=5, color_threshold=y_threshold, above_threshold_color='k')\n",
    "plt.hlines(y_threshold, 0, 1000, colors=\"r\", linestyles=\"dashed\")\n",
    "plt.title(f'Hierarchical Clustering Dendrogram: {linkage.title()} Linkage', fontsize=21)\n",
    "plt.xlabel('Number of points in node (or index of point if no parenthesis)')\n",
    "plt.ylabel(f'{distance.title()} Distance', fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the Dendrogram with y_threshold = 75\n",
    "\n",
    "# Plot the corresponding dendrogram\n",
    "sns.set()\n",
    "fig = plt.figure(figsize=(11,5))\n",
    "# The Dendrogram parameters need to be tuned\n",
    "y_threshold = 75\n",
    "dendrogram(linkage_matrix, truncate_mode='level', p=5, color_threshold=y_threshold, above_threshold_color='k')\n",
    "plt.hlines(y_threshold, 0, 1000, colors=\"r\", linestyles=\"dashed\")\n",
    "plt.title(f'Hierarchical Clustering Dendrogram: {linkage.title()} Linkage', fontsize=21)\n",
    "plt.xlabel('Number of points in node (or index of point if no parenthesis)')\n",
    "plt.ylabel(f'{distance.title()} Distance', fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Cluster Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trocar depois\n",
    "linkage = 'ward'\n",
    "distance = 'euclidean'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trocar!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = #preencher depois\n",
    "\n",
    "hcn_clust = AgglomerativeClustering(linkage=linkage, metric=distance, n_clusters=n_clusters)\n",
    "hcn_labels = hcn_clust.fit_predict(df[metric_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Characterizing the n clusters\n",
    "df_concat = pd.concat([df[metric_features], \n",
    "                       pd.Series(hcn_labels, \n",
    "                                 name='labels', \n",
    "                                 index=df.index)], \n",
    "                    axis=1)\n",
    "\n",
    "df_concat.groupby('labels').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SE NECESSARIO\n",
    "n_clusters= #preencher\n",
    "\n",
    "hcx_clust = AgglomerativeClustering(linkage=linkage, metric=distance, n_clusters=n_clusters)\n",
    "hcx_labels = hcx_clust.fit_predict(df[metric_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Characterizing the x clusters\n",
    "df_concat = pd.concat([df[metric_features], \n",
    "                       pd.Series(hcx_labels, \n",
    "                                 name='labels', \n",
    "                                 index=df.index)], \n",
    "                    axis=1)\n",
    "\n",
    "df_concat.groupby('labels').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## See crosstab \n",
    "## What does this mean?\n",
    "\n",
    "pd.crosstab(\n",
    "    pd.Series(hcx_labels, name='hc5_labels', index=df.index),\n",
    "    pd.Series(hcn_labels, name='hc4_labels', index=df.index),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Hierarchical clustering solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final cluster solution\n",
    "linkage = \"ward\"\n",
    "distance = \"euclidean\"\n",
    "n_clusters = #?\n",
    "\n",
    "hclust = AgglomerativeClustering(linkage=linkage, metric=distance, n_clusters=n_clusters)\n",
    "\n",
    "hc_labels = hclust.fit_predict(df[metric_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Characterizing the final clusters\n",
    "\n",
    "df_concat = pd.concat([\n",
    "    df[metric_features], \n",
    "    pd.Series(hc_labels, name='labels', index=df.index)\n",
    "    ], \n",
    "    axis=1)\n",
    "df_concat.groupby('labels').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nao meti nada do visualize cluster  e comparar clusters means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<a class=\"anchor\" id=\"section_4\">\n",
    "    \n",
    "# 4. K-Means Clustering\n",
    "    \n",
    "</a>\n",
    "<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
